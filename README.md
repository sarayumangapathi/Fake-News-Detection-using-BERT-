Fake-News-Detection-using-BERT-
Fake News Detection using BERT ( NLP PROJECT )
Fake News Detection using BERT

This project focuses on detecting fake news articles using **transformer-based NLP techniques**, specifically the BERT model. It compares traditional machine learning approaches like Logistic Regression and Naive Bayes with deep learning to improve classification accuracy.

---

ğŸ“ Files Included

- `fake_news_detection_bert.ipynb` â€“ BERT-based model implementation and evaluation.
- `dataset.csv` â€“ Dataset used for training and testing (e.g., Kaggle Fake News Dataset).
- `model_comparison.png` â€“ Optional: visualization comparing BERT vs traditional models (if available).

---

ğŸ¯ Objectives

- Classify news articles as real or fake
- Compare traditional ML models with BERT-based classification
- Improve accuracy using transformer architectures

---
 ğŸ› ï¸ Tools & Technologies

- Python
- Transformers Library (Hugging Face)
- Scikit-learn
- Pandas & NumPy
- BERT (Bidirectional Encoder Representations from Transformers)

---

ğŸ“Š Methodology

- Preprocessed text data (removal of stopwords, punctuation, tokenization)
- Vectorized traditional models using TF-IDF
- Fine-tuned pretrained BERT model for binary classification
- Evaluated with metrics: accuracy, precision, recall, and F1-score

---

ğŸ“ˆ Results

- BERT model outperformed baseline models in terms of accuracy and generalization
- Achieved high precision in detecting misleading or fake content

---

 ğŸ”— Data Source

Dataset used: [Fake News Dataset on Kaggle](https://www.kaggle.com/clmentbisaillon/fake-and-real-news-dataset)

---

 ğŸ‘©â€ğŸ’» Author

Sarayu Mangapathi & Likhitha yerraguntla  


---

 ğŸ“Œ Note

This project is for educational and research purposes to demonstrate the use of transformer-based models in real-world NLP classification tasks.
