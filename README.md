Fake-News-Detection-using-BERT-
Fake News Detection using BERT ( NLP PROJECT )
Fake News Detection using BERT

This project focuses on detecting fake news articles using **transformer-based NLP techniques**, specifically the BERT model. It compares traditional machine learning approaches like Logistic Regression and Naive Bayes with deep learning to improve classification accuracy.

---

📁 Files Included

- `fake_news_detection_bert.ipynb` – BERT-based model implementation and evaluation.
- `dataset.csv` – Dataset used for training and testing (e.g., Kaggle Fake News Dataset).
- `model_comparison.png` – Optional: visualization comparing BERT vs traditional models (if available).

---

🎯 Objectives

- Classify news articles as real or fake
- Compare traditional ML models with BERT-based classification
- Improve accuracy using transformer architectures

---
 🛠️ Tools & Technologies

- Python
- Transformers Library (Hugging Face)
- Scikit-learn
- Pandas & NumPy
- BERT (Bidirectional Encoder Representations from Transformers)

---

📊 Methodology

- Preprocessed text data (removal of stopwords, punctuation, tokenization)
- Vectorized traditional models using TF-IDF
- Fine-tuned pretrained BERT model for binary classification
- Evaluated with metrics: accuracy, precision, recall, and F1-score

---

📈 Results

- BERT model outperformed baseline models in terms of accuracy and generalization
- Achieved high precision in detecting misleading or fake content

---

 🔗 Data Source

Dataset used: [Fake News Dataset on Kaggle](https://www.kaggle.com/clmentbisaillon/fake-and-real-news-dataset)

---

 👩‍💻 Author

Sarayu Mangapathi & Likhitha yerraguntla  


---

 📌 Note

This project is for educational and research purposes to demonstrate the use of transformer-based models in real-world NLP classification tasks.
